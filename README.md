# ğŸ“˜ **LexiVoice â€“ AI-Powered Multilingual Legal Assistant**

### *Cross-Lingual RAG â€¢ Voice Input & Output â€¢ Pure Multilingual Embeddings â€¢ FAISS â€¢ Groq LLM*

LexiVoice is a multilingual, voice-enabled, AI-powered legal assistant designed to make legal knowledge **accessible, trustworthy, and multilingual**.
Users can ask legal questions in **any language**, and LexiVoice retrieves **English legal documents** using **pure cross-lingual embeddings** (no translation layer) and delivers **citation-backed answers**, both in text and voice.

---

## ğŸš€ **Key Features**

* ğŸ™ **Voice Input** using Whisper (supports >50 languages)
* ğŸŒ **Multilingual Queries** â€” Hindi, Tamil, French, Spanish, English, and more
* ğŸ§  **Pure Multilingual RAG** using `intfloat/multilingual-e5-large` (NO translation anywhere)
* ğŸ” **Cross-Lingual Retrieval** using FAISS cosine similarity
* ğŸ¤– **LLM Reasoning** powered by Groq (`llama-3.1-8b-instant`)
* ğŸ”Š **Voice Output** using gTTS in the userâ€™s preferred language
* ğŸ“š **Real Legal Documents** stored as structured JSON
* ğŸ“ **Citations & Source URLs** always included
* ğŸ“Š **Query Logging & Feedback Collection** via MongoDB
* ğŸ’» **Streamlit Frontend** with unified text + voice chat
* âš¡ **CPU-Friendly Deployment** â€” no GPU required

---

## ğŸ¯ **Problem LexiVoice Solves**

Legal information is:

* complicated
* difficult for non-English speakers
* unsafe to access through hallucinating chatbots

LexiVoice solves this by providing:

* ğŸ—£ multilingual understanding
* ğŸ” accurate retrieval from real legal documents
* ğŸ“ explainable answers with citations
* ğŸ”Š high-quality TTS
* ğŸ’¡ RAG pipeline optimized for trustworthiness

---

## ğŸ§  **System Architecture (Final & Correct)**

> **Pure Multilingual Embedding Pipeline â€” NO Google Translate, NO query/answer translation.**

```
User (Any Language: Speech/Text)
        â”‚
        â–¼
Whisper STT (if voice)
        â”‚
        â–¼
multilingual-e5-large Embedding (cross-lingual)
        â”‚
        â–¼
FAISS Vector Search (English legal documents)
        â”‚
        â–¼
Groq LLM (context-aware, citation-backed answer)
        â”‚
        â–¼
gTTS (in user-selected language)
        â”‚
        â–¼
Final Response (Text + Audio)
```

ğŸ’¡ *All languages are embedded into the same semantic space â†’ cross-lingual search without translation.*

---


## ğŸ— **Core Components Explained**

### **1. Embeddings â€” multilingual-e5-large**

* 100+ languages supported
* 384-dimensional dense embeddings
* Normalized vectors â†’ FAISS L2 = cosine similarity
* Pure cross-lingual semantic search

### **2. Retrieval â€” FAISS**

Each country has its own vector index:

```
india.faiss
canada.faiss
usa.faiss
```

Search:

```
embedding(query) â†’ FAISS â†’ top_k chunks
```

### **3. LLM â€” Groq (llama-3.1-8b-instant)**

* JSON-structured output:

```json
{
  "answer": "...",
  "reasoning": "...",
  "sources": [],
  "confidence": 0.0
}
```

* Citation-obligatory prompt

### **4. STT â€” Whisper (via Groq)**

* Supports multilingual speech
* Converts audio â†’ text â†’ embeddings

### **5. TTS â€” gTTS**

* Produces MP3 audio in user-selected language
* Cached to avoid regeneration

### **6. Streamlit Frontend**

* Login
* Country selection
* Unified chat (text + voice)
* Real-time audio playback
* Chat history

---

Chunking strategy:

* 500 characters
* 50 character overlap
* Sentence-aligned

---

## ğŸ› ï¸ **Setup Instructions**

### **1. Clone repo & create virtual environment**

```bash
python -m venv venv
source venv/bin/activate  # (Linux/Mac)
venv\Scripts\activate     # (Windows)
```

### **2. Install dependencies**

```bash
pip install -r requirements.txt
```

### **3. Create `.env`**

```
GROQ_API_KEY=your_groq_key
MONGODB_URI=mongodb://localhost:27017
MONGODB_DB_NAME=lexivoice
ENVIRONMENT=development
```

### **4. Build Vector Store (mandatory before first run)**

```bash
python backend/scripts/build_vector_store.py
```

### **5. Run backend**

```bash
uvicorn backend.main:app --reload
```

### **6. Run frontend**

```bash
cd frontend
streamlit run app.py
```

---

## ğŸ§ª **Testing**

Run individual test utilities:

```bash
python backend/scripts/test_retrieval.py
python backend/scripts/test_stt.py
python backend/scripts/test_tts.py
python backend/scripts/test_llm.py
```

---

## ğŸ“ˆ **Metrics & Targets**

* Retrieval recall@k â‰¥ **0.70**
* End-to-end latency < **3 seconds**
* STT accuracy > **90%**
* TTS success rate **100%**
* Zero hallucination (strict citation-based generation)

---

## ğŸ—º **Roadmap**

### Near Term

* JWT authentication
* More countries
* Improved LLM consistency

### Long Term

* Auto-scraper for legal documents
* Conversation memory
* Fine-tuned multilingual legal LLM


## ğŸ‘¨â€ğŸ’» **For Developers: Extension Points**

### â¤ Add new country

1. Add `{country}.json` â†’ `backend/data/laws`
2. Run vector store builder
3. Add country card in Streamlit

### â¤ Change embedding model

`backend/core/embeddings.py`

* Update model path & name
* Rebuild FAISS indexes

### â¤ Swap LLM model

`backend/core/llm_handler.py`

* Update `model` field
* Update token limits & temperature

---

## ğŸ“œ **License**

MIT (feel free to modify)

---

## ğŸ¤ **Contributing**

PRs welcome!
Ensure vector stores are rebuilt before committing.

---

## â­ **Credits**

Built by **Vijayenth RV**
Powered by:

* Groq
* Sentence Transformers
* FAISS
* Streamlit
* gTTS
* Whisper


